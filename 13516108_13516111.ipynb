{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mata Kuliah Intelegensi Buatan\n",
    "### Tugas Kecil 2 - Eksplokrasi scikit-learn pada Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Membaca dataset standar iris dan dataset play-tennis (dataset eksternal dalam format csv).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "# Membaca data set standar iris dari sklearn\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# membaca data csv play tennis\n",
    "weather = pd.read_csv('weather.nominal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melakukan pembelajaran Naive Bayes, Decision Tree, k-Nearest Neighbor, Artificial Neural Network (Multilayer Perceptron) untuk dataset iris dengan skema full-training, dan menampilkan modelnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Naive Bayes :\n",
      "{'priors': None, 'var_smoothing': 1e-09, 'epsilon_': 3.0955026666666677e-09, 'classes_': array([0, 1, 2]), 'theta_': array([[5.006, 3.428, 1.462, 0.246],\n",
      "       [5.936, 2.77 , 4.26 , 1.326],\n",
      "       [6.588, 2.974, 5.552, 2.026]]), 'sigma_': array([[0.121764, 0.140816, 0.029556, 0.010884],\n",
      "       [0.261104, 0.0965  , 0.2164  , 0.038324],\n",
      "       [0.396256, 0.101924, 0.298496, 0.073924]]), 'class_count_': array([50., 50., 50.]), 'class_prior_': array([0.33333333, 0.33333333, 0.33333333])}\n",
      "\n",
      "Model Decision Tree :\n",
      "{'criterion': 'gini', 'splitter': 'best', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': None, 'random_state': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'class_weight': None, 'presort': False, 'n_features_': 4, 'n_outputs_': 1, 'classes_': array([0, 1, 2]), 'n_classes_': 3, 'max_features_': 4, 'tree_': <sklearn.tree._tree.Tree object at 0x0000023B72AE76B0>}\n",
      "\n",
      "Metode pembelajaran k-NN : \n",
      "{'metric': 'euclidean', 'shrink_threshold': None, 'classes_': array([0, 1, 2]), 'centroids_': array([[5.006, 3.428, 1.462, 0.246],\n",
      "       [5.936, 2.77 , 4.26 , 1.326],\n",
      "       [6.588, 2.974, 5.552, 2.026]])}\n",
      "\n",
      "Model ANN MLP : \n",
      "{'activation': 'relu', 'solver': 'lbfgs', 'alpha': 1e-05, 'batch_size': 'auto', 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'power_t': 0.5, 'max_iter': 200, 'loss': 'log_loss', 'hidden_layer_sizes': (10, 5), 'shuffle': True, 'random_state': 1, 'tol': 0.0001, 'verbose': False, 'warm_start': False, 'momentum': 0.9, 'nesterovs_momentum': True, 'early_stopping': False, 'validation_fraction': 0.1, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-08, 'n_iter_no_change': 10, '_label_binarizer': LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False), 'classes_': array([0, 1, 2]), 'n_outputs_': 3, '_random_state': <mtrand.RandomState object at 0x0000023B72E6BE10>, 'n_iter_': 201, 't_': 0, 'n_layers_': 4, 'out_activation_': 'softmax', 'coefs_': [array([[ -1.06898121, -18.02828596,  -0.65442665,  -2.29269637,\n",
      "         -0.4624505 ,  -0.53369105,  -0.41073331,  -0.2021846 ,\n",
      "         -0.13514715,  -3.9800422 ],\n",
      "       [ -0.44607301, -30.18014598,  -0.38691715, -15.23801818,\n",
      "         -0.61872184,   0.22316801,  -0.10826065,   0.07683395,\n",
      "         -0.47078843,  -2.25469645],\n",
      "       [ -0.64760056,  60.55821471,  -0.24425625,  25.0024241 ,\n",
      "          0.4927509 ,   0.5166004 ,  -0.54324052,  -0.6034477 ,\n",
      "         -0.43224242,  -2.82663197],\n",
      "       [ -0.92972418,  43.26405527,   0.59944734,  10.86797502,\n",
      "          0.25119645,  -0.24151822,   0.2441582 ,   0.43807612,\n",
      "         -0.63063423,  -0.87200183]]), array([[-6.07886275e-01, -2.18856960e-01, -3.64721721e-01,\n",
      "        -1.50482929e-01, -5.35840090e-01],\n",
      "       [-5.78399319e-01, -3.77972978e+00, -1.64288638e+00,\n",
      "         9.13932220e+01,  3.84197557e+00],\n",
      "       [-5.02952193e-01, -1.08698697e-01,  2.45869879e-01,\n",
      "        -1.08542775e-01, -5.69201639e-01],\n",
      "       [-7.28772383e+00,  4.85514103e+00,  3.16127839e+00,\n",
      "         9.56247971e+00,  1.56245625e+00],\n",
      "       [ 5.10207302e-01, -4.58508118e-01, -4.56229469e-01,\n",
      "         3.88776736e-01, -1.29414420e-01],\n",
      "       [-4.23247202e-01,  5.40696489e-01, -1.92539914e-01,\n",
      "         3.17217548e-01,  2.85833601e-01],\n",
      "       [ 4.84790873e-01,  1.56415874e-01,  3.17382385e-01,\n",
      "        -1.91107593e-01, -2.90986396e-01],\n",
      "       [ 5.00701736e-01, -9.09475106e-02,  5.87911899e-01,\n",
      "         2.06714551e-01,  1.53916089e-01],\n",
      "       [-4.87254547e-01,  5.68496810e-01, -6.33492164e-02,\n",
      "         9.91441838e-02, -1.16185056e-01],\n",
      "       [-3.32598210e-01, -7.68941854e-01,  9.31869946e-02,\n",
      "        -1.11394846e-01, -1.38726418e+00]]), array([[ -0.02410326,  -0.60056307,   0.74350318],\n",
      "       [ -0.53026821,   0.50278855,   0.65191464],\n",
      "       [  0.58885517,   1.53297616,  -1.66020878],\n",
      "       [-22.66692672,  11.39378265,  11.40362036],\n",
      "       [ 21.36158651, -10.36743019, -10.54591941]])], 'intercepts_': [array([ 0.51337355, -9.84210152, -0.28746629, -0.41723417, -0.5194991 ,\n",
      "       -0.06822339,  0.53497709, -0.27022251, -0.27786731, -1.10741676]), array([ -0.32162506,  -0.47496305,  -2.75317136, -30.06701529,\n",
      "        48.99076674]), array([ 25.18867947,  -9.02436668, -18.63352856])], '_coef_indptr': [(0, 40, (4, 10)), (40, 90, (10, 5)), (90, 105, (5, 3))], '_intercept_indptr': [(105, 115), (115, 120), (120, 123)], 'loss_': 0.04088571497015432}\n"
     ]
    }
   ],
   "source": [
    "# Pembelajaran Fullset Training\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb_pred = gnb.fit(iris.data, iris.target)\n",
    "print(\"Model Naive Bayes :\")\n",
    "print(gnb_pred.__dict__)\n",
    "print()\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "dt_pred = clf.fit(iris.data, iris.target) \n",
    "print(\"Model Decision Tree :\")\n",
    "print(dt_pred.__dict__)\n",
    "print()\n",
    "\n",
    "# k-NN\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "import numpy as np\n",
    "clf = NearestCentroid()\n",
    "knn_pred = clf.fit(iris.data, iris.target)\n",
    "print(\"Metode pembelajaran k-NN : \")\n",
    "print(knn_pred.__dict__)\n",
    "print()\n",
    "\n",
    "# Artificial Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "ann = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(10, 5), random_state=1)\n",
    "\n",
    "ann_pred = ann.fit(iris.data, iris.target)\n",
    "print(\"Model ANN MLP : \")\n",
    "print(ann_pred.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melakukan pembelajaran NaïveBayes, DecisionTree, kNN, dan MLP untuk dataset iris dengan skema split train 90% dan test 10%, dan menampilkan kinerja serta confusion matrixnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model naive bayes : 93 persen\n",
      "Confusion Matrix :\n",
      "[[3 0 0]\n",
      " [0 8 0]\n",
      " [0 1 3]]\n",
      "\n",
      "Akurasi model decision tree : 100 persen\n",
      "Confusion Matrix :\n",
      "[[3 0 0]\n",
      " [0 8 0]\n",
      " [0 0 4]]\n",
      "\n",
      "Akurasi kNN : 86 persen\n",
      "Confusion Matrix :\n",
      "[[3 0 0]\n",
      " [0 6 2]\n",
      " [0 0 4]]\n",
      "\n",
      "Akurasi ANN : 100 persen\n",
      "Confusion Matrix :\n",
      "[[3 0 0]\n",
      " [0 8 0]\n",
      " [0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "# Pembelajaran 90% training 10% test\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_target, test_target = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.1, random_state=0)\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb_pred = gnb.fit(train_data, train_target).predict(test_data)\n",
    "accuracy = (test_target == gnb_pred).sum()/len(test_data)*100\n",
    "print(\"Akurasi model naive bayes : %d persen\" % (accuracy))\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(test_target, gnb_pred))\n",
    "print()\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "dt_pred = clf.fit(train_data, train_target).predict(test_data)\n",
    "accuracy = (dt_pred == test_target).sum()/len(test_data)*100\n",
    "print(\"Akurasi model decision tree : %d persen\" % (accuracy))\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(test_target, dt_pred))\n",
    "print()\n",
    "\n",
    "# k-NN\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "import numpy as np\n",
    "clf = NearestCentroid()\n",
    "knn = clf.fit(train_data, train_target)\n",
    "knn_pred = knn.predict(test_data)\n",
    "accuracy = (test_target == knn_pred).sum()/len(test_data)*100\n",
    "print(\"Akurasi kNN : %d persen\" % (accuracy))\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(test_target, knn_pred))\n",
    "print()\n",
    "\n",
    "# Artificial Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "ann = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(10, 5), random_state=1)\n",
    "\n",
    "ann_pred = ann.fit(train_data, train_target).predict(test_data)\n",
    "accuracy = (test_target == ann_pred).sum()/len(test_data)*100\n",
    "print(\"Akurasi ANN : %d persen\" % (accuracy))\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(test_target, ann_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melakukan pembelajaran NaïveBayes, DecisionTree, kNN, dan MLP untuk dataset iris dengan skema 10-fold cross validation, dan menampilkan kinerjanya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model naive bayes : 0.95 (+/- 0.09)\n",
      "\n",
      "Akurasi model decision tree : 0.96 (+/- 0.09)\n",
      "\n",
      "Akurasi k-NN : 0.93 (+/- 0.12)\n",
      "\n",
      "Akurasi model ANN : 0.98 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "# Pembelajaran dengan skema 10-fold cross validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb_pred = gnb.fit(train_data, train_target)\n",
    "scores = cross_val_score(gnb_pred, iris.data, iris.target, cv=10)\n",
    "print(\"Akurasi model naive bayes : %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print()\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "dt_pred = clf.fit(train_data, train_target)\n",
    "scores = cross_val_score(dt_pred, iris.data, iris.target, cv=10)\n",
    "print(\"Akurasi model decision tree : %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print()\n",
    "\n",
    "# k-NN\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "import numpy as np\n",
    "clf = NearestCentroid()\n",
    "knn_pred = clf.fit(train_data, train_target)\n",
    "scores = cross_val_score(knn_pred, iris.data, iris.target, cv=10)\n",
    "print(\"Akurasi k-NN : %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print()\n",
    "\n",
    "# Artificial Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "ann = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(10, 5), random_state=1)\n",
    "\n",
    "ann_pred = ann.fit(train_data, train_target)\n",
    "scores = cross_val_score(ann_pred, iris.data, iris.target, cv=10)\n",
    "print(\"Akurasi model ANN : %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Menyimpan (save) model/hipotesis hasil pembelajaran ke sebuah file eksternal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ann-iris.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(gnb_pred, 'gnb-iris.joblib') \n",
    "joblib.dump(dt_pred, 'dt-iris.joblib') \n",
    "joblib.dump(knn_pred, 'knn-iris.joblib') \n",
    "joblib.dump(ann_pred, 'ann-iris.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Membaca (read)model/hipotesis dari file eksternal, membuat instance baru, dan melakukan prediksi terhadap instance tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnbLoad = joblib.load('gnb-iris.joblib') \n",
    "dtLoad = joblib.load('dt-iris.joblib') \n",
    "knnLoad = joblib.load('knn-iris.joblib') \n",
    "annLoad = joblib.load('ann-iris.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klasifikasi dengan Naive Bayes : 2\n",
      "Klasifikasi dengan Decision Tree : 2\n",
      "Klasifikasi dengan kNN : 2\n",
      "Klasifikasi dengan ANN MLP : 2\n"
     ]
    }
   ],
   "source": [
    "# g. membuat instance baru dengan memberi nilai untuk setiap atribut\n",
    "newInstance = np.array([[6.0, 3.3, 6.1, 2.6]])\n",
    "\n",
    "# h. Melakukan klasifikasi dengan memanfaatkan model/hipotesisNaïveBayes, DecisionTree, dan kNN dan instance pada g.\n",
    "print(\"Klasifikasi dengan Naive Bayes : %d\" % gnbLoad.predict(newInstance))\n",
    "print(\"Klasifikasi dengan Decision Tree : %d\" % dtLoad.predict(newInstance))\n",
    "print(\"Klasifikasi dengan kNN : %d\" % knnLoad.predict(newInstance))\n",
    "print(\"Klasifikasi dengan ANN MLP : %d\" % annLoad.predict(newInstance))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
